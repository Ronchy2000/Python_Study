{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c40ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This class implements Non-linear Matrix Factorization with Gaussian Processes (NLMFGP), described in:\n",
    "    Lawrence, Neil D., and Raquel Urtasun.\n",
    "    \"Non-linear matrix factorization with Gaussian processes.\"\n",
    "    Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 2009.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel, rbf_kernel\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Add parent directory to python path\n",
    "#PACKAGE_PARENT = '..'\n",
    "#SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser(__file__))))\n",
    "#sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "sys.path.append(r'E:\\Developer\\Python\\Myworkshop\\Python_Study\\机器学习\\Matrix Factorization\\nonlin_gp_mf')\n",
    "sys.path.append(r'E:\\Developer\\Python\\Myworkshop\\Python_Study\\机器学习\\Matrix Factorization\\data_fetching')\n",
    "from data_set import DataSet\n",
    "\n",
    "\n",
    "class GpMf():\n",
    "    def __init__(self, latent_dim, nb_data):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.nb_data = nb_data\n",
    "        self.X = np.random.normal(0, 1e-3, (nb_data, latent_dim))\n",
    "        self.lin_variance = 1.0\n",
    "        self.bias_variance = 0.11\n",
    "        self.white_variance = 5.0\n",
    "        self.y = None\n",
    "        self.rated_items = None\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        \"\"\"return the log likelihood of the model\"\"\"\n",
    "        Cj_invy, logDetC = self.invert_covariance()\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        Nj = len(self.rated_items)\n",
    "        likelihood = - 0.5 * (Nj * np.log(2 * math.pi) + logDetC + yj.T.dot(Cj_invy))\n",
    "        return float(likelihood)\n",
    "\n",
    "    def invert_covariance(self, gradient=False, nonlinear =False, kernel=linear_kernel):\n",
    "        q = self.latent_dim\n",
    "        Nj = len(self.rated_items)\n",
    "        Xj = np.asmatrix(self.X[self.rated_items, :])\n",
    "        #print(\"self.rated_items.shape:\",self.rated_items.shape)\n",
    "        #print(\"invert_covariance----self.X[self.rated_items, :]:\",self.X[self.rated_items, :])\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        s_n = self.white_variance\n",
    "        s_w = self.lin_variance\n",
    "        s_b = self.bias_variance\n",
    "        sigNoise = s_w / s_n\n",
    "\n",
    "        if Nj > q and not nonlinear: # we use the matrix inversion lemma\n",
    "            XTX = Xj.T * Xj\n",
    "            B = np.eye(q) + sigNoise * XTX\n",
    "            Binv = np.linalg.pinv(B)\n",
    "            _, logdetB = np.linalg.slogdet(B)\n",
    "            if gradient:\n",
    "                AinvX = (Xj - sigNoise * Xj * (Binv * XTX)) / s_n\n",
    "                AinvTr = (Nj - sigNoise * (np.multiply(Xj * Binv, Xj)).sum()) / s_n\n",
    "            Ainvy = (yj - sigNoise * Xj * (Binv * (Xj.T * yj))) / s_n\n",
    "            sumAinv = (np.ones((Nj, 1)) - sigNoise * Xj * (Binv * Xj.sum(axis=0).T)) / s_n  # this is Nx1\n",
    "            sumAinvSum = sumAinv.sum()\n",
    "            denom = 1 + s_b * sumAinvSum\n",
    "            fact = s_b / denom\n",
    "            if gradient:\n",
    "                CinvX = AinvX - fact * sumAinv * (sumAinv.T * Xj)\n",
    "                CinvSum = sumAinv - fact * sumAinv * sumAinvSum\n",
    "                CinvTr = AinvTr - fact * sumAinv.T * sumAinv\n",
    "\n",
    "            Cinvy = Ainvy - fact * sumAinv * float(sumAinv.T * yj)\n",
    "            if not gradient:\n",
    "                logdetA = Nj * np.log(s_n) + logdetB\n",
    "                logdetC = logdetA + np.log(denom)\n",
    "\n",
    "        else :\n",
    "            C = s_w * kernel(Xj, Xj)\n",
    "            C = C + s_b + s_n * np.eye(Nj)\n",
    "            Cinv = np.linalg.pinv(C)\n",
    "            Cinvy = Cinv * yj\n",
    "            if gradient:\n",
    "                CinvX = Cinv * Xj\n",
    "                CinvTr = np.trace(Cinv)\n",
    "                CinvSum = Cinv.sum(axis=1)\n",
    "            else:\n",
    "                _, logdetC = np.linalg.slogdet(C)\n",
    "\n",
    "        if gradient:\n",
    "            return Cinvy, CinvSum, CinvX, CinvTr\n",
    "        else:\n",
    "            return Cinvy, logdetC\n",
    "\n",
    "    def log_likelihood_grad(self, ):\n",
    "        \"\"\"Computes the gradient of the log likelihood\"\"\"\n",
    "        s_w = self.lin_variance\n",
    "        s_b = self.bias_variance\n",
    "        s_n = self.white_variance\n",
    "\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        Xj = np.asmatrix(self.X[self.rated_items, :])\n",
    "\n",
    "        Cinvy, CinvSum, CinvX, CinvTr = self.invert_covariance(gradient=True)\n",
    "        covGradX = 0.5 * (Cinvy * (Cinvy.T * Xj) - CinvX)\n",
    "        gX = s_w * 2.0 * covGradX\n",
    "        gsigma_w = np.multiply(covGradX, Xj).sum()\n",
    "        CinvySum = Cinvy.sum()\n",
    "        CinvSumSum = CinvSum.sum()\n",
    "        gsigma_b = 0.5 * (CinvySum * CinvySum - CinvSumSum)\n",
    "        gsigma_n = 0.5 * (Cinvy.T * Cinvy - CinvTr)\n",
    "        return gX, float(gsigma_w), float(gsigma_b), float(gsigma_n)\n",
    "\n",
    "    def objective(self):\n",
    "        return -self.log_likelihood()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598b9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(dataset, model, nb_iter=10, seed=42, momentum=0.9):\n",
    "    data = dataset.get_df()\n",
    "    param_init = np.zeros((1, 3))\n",
    "    X_init = np.zeros(model.X.shape)\n",
    "    for iter in range(nb_iter):\n",
    "        print(\"iteration\", iter)\n",
    "        tic = time.time()\n",
    "        np.random.seed(seed=seed)\n",
    "        state = np.random.get_state()\n",
    "        users = np.random.permutation(dataset.get_users())\n",
    "        for user in users:\n",
    "            #print(\"begin user\", user,  \"=========================\")\n",
    "            toc = time.time()\n",
    "            lr = 1e-4\n",
    "            y = dataset.get_ratings_user(user)\n",
    "            #print('dataset.get_ratings_user(user):', y)\n",
    "            #获取每个人的评分，打印结果如下：\n",
    "            #dataset.get_ratings_user(user): [3 5 5 5 5 5 3 4 5 5 5 4 5 4 5 4 5 3 4 4 5 5 4 1 5 5 5 5 4 4 5 5 5 3 5 3 5\n",
    "            #                                 3 5 2 5 5 5 5 5 4 4 4 5 5 2 1 1 5 2 5 4 3 3 4 5 5]\n",
    "            #dataset.get_ratings_user(user): [3 2 4 4 4 4 3 4 4 3 4 5 4 3 2 1 3 3 5 1 3 2]\n",
    "            #dataset.get_ratings_user(user): [5 3 5 4 3 5 5 4 2 4 5 4 5 4 5 4 3 5 3 4]\n",
    "            #获取每个人的评分的（影片ID-1）\n",
    "            rated_items = dataset.get_items_user(user) - 1\n",
    "\n",
    "            model.y = y\n",
    "            model.rated_items = rated_items\n",
    "            #print(\"model.rated_items:\",model.rated_items)\n",
    "            grad_X, grad_w, grad_b, grad_n = model.log_likelihood_grad()\n",
    "            gradient_param = np.array([grad_w * model.lin_variance,\n",
    "                               grad_b * model.bias_variance,\n",
    "                               grad_n * model.white_variance])\n",
    "            param = np.log(np.array([model.lin_variance,\n",
    "                                     model.bias_variance,\n",
    "                                     model.white_variance]))\n",
    "            # update X\n",
    "            X = X_init[rated_items, :]\n",
    "            ar = lr * 10\n",
    "            X = X * momentum + grad_X * ar\n",
    "            X_init[rated_items, :] = X\n",
    "            model.X[rated_items, :] = model.X[rated_items, :] + X\n",
    "\n",
    "            # update variances\n",
    "            param_init = param_init * momentum + gradient_param * lr\n",
    "            param = param + param_init\n",
    "            model.lin_variance = math.exp(param[0, 0])\n",
    "            model.bias_variance = math.exp(param[0, 1])\n",
    "            model.white_variance = math.exp(param[0, 2])\n",
    "            #print(\"end user\", user, \"=========================\")\n",
    "\n",
    "        print(\"end iteration\", iter,  \"=========================\")\n",
    "        print(\"duration iteration\", time.time() - tic)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d92a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user, test_items, model, dataset):\n",
    "    y = dataset.get_ratings_user(user)\n",
    "    rated_items = dataset.get_items_user(user) - 1\n",
    "    model.rated_items = rated_items\n",
    "    model.y = y\n",
    "    X_test = np.asmatrix(model.X[test_items, :])\n",
    "    X = np.asmatrix(model.X[model.rated_items, :])\n",
    "#     print(\"test_items:\",test_items,test_items.shape)\n",
    "    print(\"X:\",X.shape)\n",
    "    print(\"X_test:\", X_test.shape)\n",
    "    print(\"model.X[test_items, :]\",model.X[test_items, :].shape)\n",
    "    print(\"model.X[model.rated_items, :]\",model.X[model.rated_items, :].shape)\n",
    "    \n",
    "    Cinvy, CinvSum, CinvX, CinvTr = model.invert_covariance(gradient=True)\n",
    "    mean = model.lin_variance* X_test*(X.T*Cinvy) + Cinvy.sum() * model.bias_variance\n",
    "    return mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f7eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_weak(dataset, base_dim=9):\n",
    "    print('Fetch data set...')\n",
    "    if dataset.dataset == \"movielens\":\n",
    "        norm_coeff = 1.6\n",
    "        print(\"norm_coeff:1.6------------\")\n",
    "    else :\n",
    "        norm_coeff = 6.67\n",
    "    print('Data set fetched')\n",
    "    print(\"Dataset desctiption\", dataset.get_description())\n",
    "    model_init = GpMf(latent_dim=base_dim, nb_data=dataset.item_index_range)\n",
    "    print('Fit the model...')\n",
    "    model = fit(dataset=dataset, model=model_init)\n",
    "    print('Model fitted')\n",
    "    predictions = []\n",
    "    true_ratings = []\n",
    "    test_users = dataset.get_users_test()\n",
    "    nb_users_test = len(test_users)\n",
    "    print(\"nb_users\", nb_users_test)\n",
    "    count = 0\n",
    "    for user in test_users:\n",
    "        prediction = predict(user, dataset.get_item_test(user) - 1, model, dataset)\n",
    "        print( \"prediction: \",prediction )\n",
    "\n",
    "        if prediction > dataset.high_rating:\n",
    "            prediction = dataset.high_rating\n",
    "        if prediction < dataset.low_rating:\n",
    "            prediction = dataset.low_rating\n",
    "        predictions.append(prediction)\n",
    "        rating = dataset.get_rating_test(user)\n",
    "        true_ratings.append(rating)\n",
    "        count += 1\n",
    "        print(count, \"over \", nb_users_test, \"users\")\n",
    "    predictions = np.asarray(predictions)\n",
    "    true_ratings = np.asarray(true_ratings)\n",
    "    rmse = np.linalg.norm(predictions - true_ratings) / np.sqrt(nb_users_test)\n",
    "    nmae = np.sum(np.abs(true_ratings - predictions)) * 1. / (len(predictions) * norm_coeff)\n",
    "    print(\"rmse\", rmse)\n",
    "    print(\"nmae\", nmae)\n",
    "    return float(rmse), float(nmae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa01632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== DEMO ======================================================================================\n",
    "def plot_errors_vs_latent_dims():\n",
    "    #base_dims = range(5, 30)  #latent feature = 9,最好\n",
    "    base_dims = 9\n",
    "    rmse_res = []\n",
    "        #0.9192805345815771, 0.9191762806556765, 0.9298582192495648, 0.9264887573748214, 0.942721413670847,\n",
    "        #0.9464276649204383, 0.9619938797137044, 0.959524838407498, 0.9637647705458857, 0.9654112679112156,\n",
    "        #0.964014562524729, 0.9828162923399141, 0.9791815989138641, 0.9755912980143179, 0.9909916313775403]\n",
    "    nmae_res = []\n",
    "        #0.44971496453721255, 0.44916990674349777, 0.4520802986328138, 0.45121143493891314, 0.45841600020196077,\n",
    "        #0.4600831341641973, 0.46819195277564857, 0.4653186575931832, 0.4675059307434209, 0.46521752440367997,\n",
    "        #0.4693989965956004, 0.4749311584164483, 0.47302261002602103, 0.47072878663284334, 0.4775780782441432]\n",
    "\n",
    "    if not len(rmse_res):\n",
    "        dataset_movielens_s = DataSet(dataset=\"movielens\", size=\"S\")\n",
    "        for dim in base_dims:\n",
    "            (rmse, nmae) = perf_weak(dataset=dataset_movielens_s, base_dim=dim)\n",
    "            rmse_res.append(rmse)\n",
    "            nmae_res.append(nmae)\n",
    "\n",
    "        print(rmse_res)\n",
    "        print(nmae_res)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(base_dims, rmse_res, marker='.')\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of latent dimensions ($r$)')\n",
    "    plt.ylabel('RMSE (MovieLens 100k)')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(base_dims, nmae_res, marker='*')\n",
    "    plt.xlabel('Number of latent dimensions ($r$)')\n",
    "    plt.ylabel('NMAE (MovieLens 100k)')\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e46afdd",
   "metadata": {},
   "source": [
    "# if __name__ == \"__main__\":\n",
    "    print('START')\n",
    "    # MovieLens dataset 100k\n",
    "    perf_weak(dataset=DataSet(dataset=\"movielens\", size=\"S\"))\n",
    "    # MovieLens dataset 1M\n",
    "    #perf_weak(dataset=DataSet(dataset=\"movielens\", size=\"M\"))\n",
    "    # Toy dataset\n",
    "    #perf_weak(dataset=DataSet(dataset=\"toy\"))\n",
    "    # Jester dataset\n",
    "    #perf_weak(dataset=DataSet(dataset=\"jester\"))\n",
    "    plot_errors_vs_latent_dims()\n",
    "    print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a974294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Fetch data set...\n",
      "norm_coeff:1.6------------\n",
      "Data set fetched\n",
      "Dataset desctiption {'Number of users': 943, 'Number of items': 1682, 'Lowest user': 1, 'Highest user': 943, 'Density': 0.06304669364224531, 'Mean of ratings': 3.52986, 'Standard deviation of ratings': 1.125667970762062}\n",
      "Fit the model...\n",
      "iteration 0\n"
     ]
    }
   ],
   "source": [
    "print('START')\n",
    "dataset=DataSet(dataset=\"movielens\", size=\"S\")\n",
    "base_dim = 9\n",
    "#----------------------------------------------------\n",
    "print('Fetch data set...')\n",
    "if dataset.dataset == \"movielens\":\n",
    "    norm_coeff = 1.6\n",
    "    print(\"norm_coeff:1.6------------\")\n",
    "else :\n",
    "    norm_coeff = 6.67\n",
    "print('Data set fetched')\n",
    "print(\"Dataset desctiption\", dataset.get_description())\n",
    "model_init = GpMf(latent_dim=base_dim, nb_data=dataset.item_index_range)\n",
    "print('Fit the model...')\n",
    "model = fit(dataset=dataset, model=model_init)\n",
    "print('Model fitted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84287f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "true_ratings = []\n",
    "test_users = dataset.get_users_test()\n",
    "nb_users_test = len(test_users)\n",
    "print(\"nb_users\", nb_users_test)\n",
    "count = 0\n",
    "for user in test_users:\n",
    "    prediction = predict(user, dataset.get_item_test(user) - 1, model, dataset)\n",
    "    print(\"dataset.get_item_test(user) - 1:\",dataset.get_item_test(user) - 1)\n",
    "    print( \"prediction: \",prediction )\n",
    "\n",
    "    if prediction > dataset.high_rating:\n",
    "        prediction = dataset.high_rating\n",
    "    if prediction < dataset.low_rating:\n",
    "        prediction = dataset.low_rating\n",
    "    predictions.append(prediction)\n",
    "    rating = dataset.get_rating_test(user)\n",
    "    true_ratings.append(rating)\n",
    "    count += 1\n",
    "    print(count, \"over \", nb_users_test, \"users\")\n",
    "predictions = np.asarray(predictions)\n",
    "true_ratings = np.asarray(true_ratings)\n",
    "rmse = np.linalg.norm(predictions - true_ratings) / np.sqrt(nb_users_test)\n",
    "nmae = np.sum(np.abs(true_ratings - predictions)) * 1. / (len(predictions) * norm_coeff)\n",
    "print(\"rmse\", rmse)\n",
    "print(\"nmae\", nmae)\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5c1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myML] *",
   "language": "python",
   "name": "conda-env-myML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
